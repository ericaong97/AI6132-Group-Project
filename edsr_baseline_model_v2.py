# -*- coding: utf-8 -*-
"""EDSR Baseline Model_v2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ajBJklXM3dI9A2gYwaGtHBpftESj7iu6
"""

lowres, highres = next(iter(train_ds))

# High Resolution Images
plt.figure(figsize=(10, 10))
for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(highres[i].numpy().astype("uint8"))
    plt.title(highres[i].shape)
    plt.axis("off")

# Low Resolution Images
plt.figure(figsize=(10, 10))
for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(lowres[i].numpy().astype("uint8"))
    plt.title(lowres[i].shape)
    plt.axis("off")

import os
import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

from tensorflow import keras
from tensorflow.keras import layers

# --- CRITICAL MEMORY CONFIGURATION (Place at the very beginning) ---
# This prevents TensorFlow from pre-allocating all VRAM, allowing memory to grow
# only as needed, which stabilizes multi-process environments and large models.
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        # Restrict TensorFlow to only use the first GPU
        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')
        # Enable memory growth
        tf.config.experimental.set_memory_growth(gpus[0], True)
        print("TensorFlow GPU memory growth enabled for stability.")
    except RuntimeError as e:
        # Memory growth must be set before GPUs have been initialized
        print(e)
# -------------------------------------------------------------------


# --- Global Constants ---
AUTOTUNE = tf.data.AUTOTUNE
# AGGRESSIVE MEMORY FIX 1: Reduced batch size from 8 to 4 for stability.
BATCH_SIZE = 4
# Change requested by user: Set total epochs to 30
EPOCHS = 30
BEST_WEIGHTS_PATH = "best-model.weights.h5"
# Change requested by user: HR crop size set back to 96 pixels (LR is 24x24)
HR_CROP_SIZE = 96
STEPS_PER_EPOCH = 50


# --- Custom Loss and Metric Functions (Corrected for Scaling) ---

def mae_normalized_loss(y_true, y_pred):
    """
    Mean Absolute Error (L1 Loss) that ensures the ground truth (y_true)
    is normalized to [0, 1] before calculating the error, matching the
    scale of the model's output (y_pred, which is [0, 1] due to sigmoid).
    """
    # 1. Cast y_true to float32
    y_true_float = tf.cast(y_true, tf.float32)

    # 2. Normalize y_true (HR image) to the [0.0, 1.0] range
    y_true_normalized = y_true_float / 255.0

    # 3. Calculate MAE on the matched scale
    return tf.reduce_mean(tf.abs(y_true_normalized - y_pred))

def psnr_corrected(y_true, y_pred):
    """
    Calculates Peak Signal-to-Noise Ratio (PSNR) correctly by ensuring
    y_true (ground truth) is cast to float32 and normalized to
    match y_pred (model output, assumed to be [0, 1]).
    """
    # 1. Cast y_true to float32
    y_true_float = tf.cast(y_true, tf.float32)

    # 2. Normalize y_true (HR image) to the [0.0, 1.0] range
    y_true_normalized = y_true_float / 255.0

    # 3. Calculate PSNR using the normalized range (max_val=1.0)
    return tf.image.psnr(y_true_normalized, y_pred, max_val=1.0)


# --- Data Pipeline Functions (from Kaggle Notebook) ---

def flip_left_right(lowres_img, highres_img):
    rn = tf.random.uniform(shape=(), maxval=1)
    return tf.cond(
        rn < 0.5,
        lambda: (lowres_img, highres_img),
        lambda: (
            tf.image.flip_left_right(lowres_img),
            tf.image.flip_left_right(highres_img),
        ),
    )

def random_rotate(lowres_img, highres_img):
    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)
    return tf.image.rot90(lowres_img, rn), tf.image.rot90(highres_img, rn)

# Uses the new, larger HR_CROP_SIZE (96)
def random_crop(lowres_img, highres_img, hr_crop_size=HR_CROP_SIZE, scale=4):
    lowres_crop_size = hr_crop_size // scale # This will be 96 // 4 = 24
    lowres_img_shape = tf.shape(lowres_img)[:2]

    # Calculate max crop dimensions safely
    lowres_max_h = tf.maximum(0, lowres_img_shape[0] - lowres_crop_size + 1)
    lowres_max_w = tf.maximum(0, lowres_img_shape[1] - lowres_crop_size + 1)

    lowres_width = tf.random.uniform(
        shape=(), maxval=lowres_max_w, dtype=tf.int32
    )
    lowres_height = tf.random.uniform(
        shape=(), maxval=lowres_max_h, dtype=tf.int32
    )

    highres_width = lowres_width * scale
    highres_height = lowres_height * scale

    lowres_img_cropped = lowres_img[
        lowres_height : lowres_height + lowres_crop_size,
        lowres_width : lowres_width + lowres_crop_size,
    ]
    highres_img_cropped = highres_img[
        highres_height : highres_height + hr_crop_size,
        highres_width : highres_width + hr_crop_size,
    ]

    return lowres_img_cropped, highres_img_cropped

def dataset_object(dataset, training=True):
    ds = dataset
    # CRITICAL STABILITY FIX: Reducing num_parallel_calls to 1.
    ds = ds.map(
        lambda lowres, highres: random_crop(lowres, highres, hr_crop_size=HR_CROP_SIZE, scale=4),
        num_parallel_calls=1, # Reduced parallelism
    )

    if training:
        # Apply data augmentation
        ds = ds.map(random_rotate, num_parallel_calls=1) # Reduced parallelism
        ds = ds.map(flip_left_right, num_parallel_calls=1) # Reduced parallelism

    # Batching Data (using the new global BATCH_SIZE=4)
    ds = ds.batch(BATCH_SIZE)

    if training:
        # Repeating Data
        ds = ds.repeat()

    ds = ds.prefetch(buffer_size=AUTOTUNE)
    return ds


# --- Model Architecture Functions ---

def ResBlock(inputs):
    # Dynamically get the number of filters from the input tensor
    num_filters = inputs.shape[-1]

    x = layers.Conv2D(num_filters, 3, padding="same", activation="relu")(inputs)
    x = layers.Conv2D(num_filters, 3, padding="same")(x)
    x = layers.Add()([inputs, x])
    return x

def Upsampling(inputs, factor=4, **kwargs):
    # Learn high-depth features
    x = layers.Conv2D(64 * (factor ** 2), 3, padding="same", **kwargs)(inputs)

    # Keras 3 Compatibility FIX: Wrap tf.nn.depth_to_space in a Lambda layer
    x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, block_size=factor),
                      name=f"pixel_shuffle_{factor}x")(x)

    return x

def make_model(num_filters, num_of_residual_blocks):
    # Flexible Inputs
    input_layer = layers.Input(shape=(None, None, 3))

    # Scaling Low-Res Input Pixel Values to [0, 1]
    x = layers.Rescaling(scale=1.0 / 255)(input_layer)

    # From the paper (Initial feature extraction)
    x = x_new = layers.Conv2D(num_filters, 3, padding="same")(x)

    # 8 residual blocks (Already reduced for memory stability)
    for _ in range(num_of_residual_blocks):
        x_new = ResBlock(x_new)

    x_new = layers.Conv2D(num_filters, 3, padding="same")(x_new)
    x = layers.Add()([x, x_new])

    # Upsampled, using Pixel Shuffle (Upscaling factor 4)
    x = Upsampling(x, factor=4)

    # Final convolution, to get it to 3 channels output
    # CRITICAL FIX: Add sigmoid to constrain output to [0, 1]
    x = layers.Conv2D(3, 3, padding="same", activation="sigmoid")(x)

    # The output is kept [0, 1] to match the normalized loss/metric functions.
    output_layer = x

    return keras.Model(input_layer, output_layer)


# --- Execution Block ---

# 1. Load Data
train, _ = tfds.load('div2k/bicubic_x4', split='train', as_supervised=True, with_info=True)
val, _ = tfds.load('div2k/bicubic_x4', split='validation', as_supervised=True, with_info=True)

train_ds = dataset_object(train, training=True)
val_ds = dataset_object(val, training=False)

# --- Data Visualization Check (User Requested - Plotted side-by-side) ---
# Samples one batch from the training data for visual inspection.
lowres, highres = next(iter(train_ds))

plt.figure(figsize=(12, 6))

# Low Resolution Images (LR_CROP_SIZE x LR_CROP_SIZE, e.g., 24x24)
plt.subplot(1, 2, 1)
plt.imshow(lowres[0].numpy().astype("uint8"), interpolation='nearest')
plt.title(f"Low Resolution Input (Batch 1, Shape: {lowres[0].shape.as_list()})", fontsize=10)
plt.axis("off")

# High Resolution Images (HR_CROP_SIZE x HR_CROP_SIZE, e.g., 96x96)
plt.subplot(1, 2, 2)
plt.imshow(highres[0].numpy().astype("uint8"))
plt.title(f"High Resolution Target (Batch 1, Shape: {highres[0].shape.as_list()})", fontsize=10)
plt.axis("off")

print("Data Visualization Check: LR and HR images successfully sampled and plotted side-by-side.")
# --------------------------------------------------------------------------------------------


# 2. Build Model
# Using 8 residual blocks and 32 filters
model = make_model(num_filters=32, num_of_residual_blocks=8)

# 3. Optimizer setup
optim_edsr = keras.optimizers.Adam(
    learning_rate=keras.optimizers.schedules.PiecewiseConstantDecay(
        boundaries=[5000], values=[1e-4, 5e-5]
    ),
)

# 4. Compile Model (Using Corrected Loss and Metric)
model.compile(optimizer=optim_edsr, loss=mae_normalized_loss, metrics=[psnr_corrected])

# 5. Checkpoint Callback
save_best_cb = keras.callbacks.ModelCheckpoint(
    filepath=BEST_WEIGHTS_PATH,
    monitor="val_loss",
    save_best_only=True,
    save_weights_only=True,
    save_freq="epoch",
)

# --- Resume Logic: Check for and Load Checkpoint Weights ---
# NOTE: Removed existing logic to force a fresh start with new HR_CROP_SIZE,
# as old weights are not compatible with the new input shape.
if os.path.exists(BEST_WEIGHTS_PATH):
    print(f"Old checkpoint found at {BEST_WEIGHTS_PATH}. Starting fresh due to change in HR_CROP_SIZE.")
# -----------------------------------------------------------


# 6. Train Model
print("\nStarting training with **HR_CROP_SIZE=96** (LR=24x24). Monitoring memory closely!")
print(f"New configuration: BATCH_SIZE={BATCH_SIZE}, HR_CROP_SIZE={HR_CROP_SIZE}, STEPS_PER_EPOCH={STEPS_PER_EPOCH}.")
history = model.fit(
    train_ds,
    epochs=EPOCHS,
    # Using the reduced steps per epoch
    steps_per_epoch=STEPS_PER_EPOCH,
    validation_data=val_ds,
    callbacks=[save_best_cb]
)

# 7. Load Best Training Weights (Example)
model.load_weights(BEST_WEIGHTS_PATH)
print("\nTraining complete. Best weights loaded.")

# --- 8. Training History Analysis (User Requested - Loss/PSNR Plots) ---
print("Plotting training history...")
plt.figure(figsize=(15, 5))

# Plotting Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss (MAE)')
plt.plot(history.history['val_loss'], label='Validation Loss (MAE)')
plt.title('Loss History')
plt.xlabel('Epoch')
plt.ylabel('MAE Loss')
plt.legend()
plt.grid(True)

# Plotting PSNR
plt.subplot(1, 2, 2)
plt.plot(history.history['psnr_corrected'], label='Training PSNR')
plt.plot(history.history['val_psnr_corrected'], label='Validation PSNR')
plt.title('PSNR History')
plt.xlabel('Epoch')
plt.ylabel('PSNR (dB)')
plt.legend()
plt.grid(True)

# We skip the plot show command to prevent blocking the rest of the script.
print("Training history plots generated successfully.")
# ------------------------------------------

!unzip bsd100.zip

import os
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
# CRITICAL FIX: Added import for PIL (Python Imaging Library) to handle image loading
from PIL import Image

from tensorflow import keras
from tensorflow.keras import layers

# --- Global Constants (Must match training script) ---
BEST_WEIGHTS_PATH = "best-model.weights.h5"
# Path to the extracted BSDS100 4x validation images
BSDS100_HR_PATH = "./bicubic_4x/val/HR/"
BSDS100_LR_PATH = "./bicubic_4x/val/LR/"
DATASET_DISPLAY_NAME = "BSDS100 (4x Validation Split)"
# Set to 20 to test on the full validation set from the zip
NUM_TEST_IMAGES = 20
# The specific image ID you want to plot
TARGET_IMAGE_ID = "102061"


# --- Model Architecture Functions (Copied from edsr_training.py) ---

def ResBlock(inputs):
    """EDSR Residual Block."""
    num_filters = inputs.shape[-1]
    x = layers.Conv2D(num_filters, 3, padding="same", activation="relu")(inputs)
    x = layers.Conv2D(num_filters, 3, padding="same")(x)
    x = layers.Add()([inputs, x])
    return x

def Upsampling(inputs, factor=4, **kwargs):
    """Pixel Shuffle/Sub-pixel convolution layer for 4x upscaling."""
    # This filter count (64) is part of the EDSR architecture definition
    # for the upsampling block and does not need to match num_filters (32).
    x = layers.Conv2D(64 * (factor ** 2), 3, padding="same", **kwargs)(inputs)
    x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, block_size=factor),
                      name=f"pixel_shuffle_{factor}x")(x)

    return x

def make_model(num_filters, num_of_residual_blocks):
    """Constructs the EDSR Model architecture."""
    input_layer = layers.Input(shape=(None, None, 3))
    x = layers.Rescaling(scale=1.0 / 255)(input_layer)
    x = x_new = layers.Conv2D(num_filters, 3, padding="same")(x)

    for _ in range(num_of_residual_blocks):
        x_new = ResBlock(x_new)

    x_new = layers.Conv2D(num_filters, 3, padding="same")(x_new)
    x = layers.Add()([x, x_new])
    x = Upsampling(x, factor=4)

    # Output is normalized [0, 1]
    output_layer = layers.Conv2D(3, 3, padding="same", activation="sigmoid")(x)
    return keras.Model(input_layer, output_layer)

# --- Metric Functions (Copied from edsr_training.py) ---
def psnr_corrected(y_true, y_pred):
    """Calculates PSNR for inputs normalized to [0, 1]."""
    y_true_float = tf.cast(y_true, tf.float32)
    y_true_normalized = y_true_float / 255.0
    return tf.image.psnr(y_true_normalized, y_pred, max_val=1.0)

def ssim_corrected(y_true, y_pred):
    """Calculates SSIM for inputs normalized to [0, 1]."""
    y_true_float = tf.cast(y_true, tf.float32)
    y_true_normalized = y_true_float / 255.0
    return tf.image.ssim(y_true_normalized, y_pred, max_val=1.0)


# --- Inference Function ---
def upscale_image(model, lowres_np):
    """
    Takes (H, W, C) LR image (as a NumPy array) and returns (4H, 4W, C)
    SR image (as a NumPy array) using the EDSR model.
    """
    # 1. Prepare the LR image for model prediction
    # Convert NumPy array to TensorFlow tensor
    model_inputs = tf.convert_to_tensor(lowres_np, dtype=tf.uint8)
    model_inputs = tf.expand_dims(model_inputs, axis=0) # (1, H, W, C), uint8

    # 2. Forward pass: SR output is [0, 1] float32
    SR = model(model_inputs, training=False)

    # 3. Denormalize, clip, round, and cast to uint8 [0, 255]
    SR = SR * 255.0
    SR = tf.clip_by_value(SR, 0, 255)
    SR = tf.round(SR)
    SR = tf.cast(SR, tf.uint8)

    # 4. Remove the batch dimension and convert back to NumPy
    SR = tf.squeeze(SR, axis=0).numpy()

    return SR

# --- Utility Functions for Analysis ---

def get_bicubic_upscale(lowres_np):
    """Performs 4x Bicubic interpolation for the baseline comparison."""
    # Convert NumPy array to PIL Image
    lr_pil = Image.fromarray(lowres_np)
    hr_shape = (lr_pil.width * 4, lr_pil.height * 4)

    # Perform 4x Bicubic interpolation using PIL
    bicubic_pil = lr_pil.resize(hr_shape, Image.BICUBIC)

    # Convert back to NumPy array
    return np.array(bicubic_pil)

def calculate_metrics(hr_img_np, upscaled_img_np):
    """
    Calculates PSNR and SSIM between ground truth (HR) and an upscaled image.
    CRITICAL FIX: Handles potential 1-pixel mismatches by cropping the HR image
    to match the upscaled image dimensions.
    """
    # Convert NumPy arrays to Tensors for metric calculation
    hr_tensor = tf.convert_to_tensor(hr_img_np, dtype=tf.float32)
    upscaled_tensor = tf.convert_to_tensor(upscaled_img_np, dtype=tf.float32)

    # Get shapes
    hr_shape = tf.shape(hr_tensor)
    upscaled_shape = tf.shape(upscaled_tensor)

    # CRITICAL FIX: Crop the HR image to match the upscaled image's dimensions
    # This handles cases where original HR dims (e.g., 321x481) don't match
    # the 4x upscale of the LR image (e.g., 320x480).
    hr_tensor_cropped = hr_tensor[:upscaled_shape[0], :upscaled_shape[1], :]

    # Calculate metrics using the corrected [0, 1] scale functions
    # We pass the [0, 255] tensors directly; the functions handle normalization
    # Note: upscaled_tensor is [0, 255], so it needs normalization for the metric fn
    psnr_val = psnr_corrected(hr_tensor_cropped, upscaled_tensor / 255.0).numpy()
    ssim_val = ssim_corrected(hr_tensor_cropped, upscaled_tensor / 255.0).numpy()

    return psnr_val, ssim_val

def plot_results(lowres, bicubic, sr, highres, psnr_bicubic, ssim_bicubic, psnr_edsr, ssim_edsr, image_id):
    """Plots the 4 comparison images."""

    plt.figure(figsize=(18, 18))

    # 1. Low Resolution Input
    plt.subplot(2, 2, 1)
    plt.imshow(lowres)
    plt.title(f"A. Low Resolution Input ({lowres.shape[0]}x{lowres.shape[1]})", fontsize=14)
    plt.axis('off')

    # 2. Bicubic Upscaling (Baseline)
    plt.subplot(2, 2, 2)
    plt.imshow(bicubic)
    plt.title(f"B. Bicubic Baseline (PSNR: {psnr_bicubic:.2f} dB | SSIM: {ssim_bicubic:.4f})", fontsize=14)
    plt.axis('off')

    # 3. EDSR Model Output (SR)
    plt.subplot(2, 2, 3)
    plt.imshow(sr)
    plt.title(f"C. EDSR Output (PSNR: {psnr_edsr:.2f} dB | SSIM: {ssim_edsr:.4f})", fontsize=14, color='darkgreen', fontweight='bold')
    plt.axis('off')

    # 4. High Resolution Ground Truth
    plt.subplot(2, 2, 4)
    plt.imshow(highres)
    plt.title(f"D. High Resolution Ground Truth ({highres.shape[0]}x{highres.shape[1]})", fontsize=14)
    plt.axis('off')

    plt.suptitle(f"Qualitative Comparison: Image '{image_id}' (4x Factor)", fontsize=16, fontweight='bold')
    # Save the figure instead of showing it to prevent blocking
    plt.savefig(f"comparison_{image_id}.png")
    print(f"   Qualitative comparison plot saved to comparison_{image_id}.png")


def load_bsds100_local(hr_folder_path, lr_folder_path):
    """
    Loads HR and matching LR images from local folders.
    Uses PIL for image loading.
    """
    print(f"   Loading HR images from local path: {hr_folder_path}")
    print(f"   Loading LR images from local path: {lr_folder_path}")

    # Find all .png or .jpg images in the HR directory
    hr_image_paths = tf.io.gfile.glob(os.path.join(hr_folder_path, "*.png"))
    hr_image_paths.extend(tf.io.gfile.glob(os.path.join(hr_folder_path, "*.jpg")))

    if not hr_image_paths:
        raise FileNotFoundError(f"No images (.png or .jpg) found in directory: {hr_folder_path}. "
                              "Please ensure you have unzipped the bsd100.zip file correctly.")

    dataset = []
    for img_path in hr_image_paths:
        try:
            image_id = os.path.splitext(os.path.basename(img_path))[0]

            # Load HR image
            hr_pil = Image.open(img_path).convert('RGB')
            hr_np = np.array(hr_pil)

            # --- UPDATED LOGIC ---
            # Construct the path to the matching LR image
            # Check for .png first, then .jpg
            lr_img_path = os.path.join(lr_folder_path, f"{image_id}.png")
            if not os.path.exists(lr_img_path):
                 lr_img_path = os.path.join(lr_folder_path, f"{image_id}.jpg")
                 if not os.path.exists(lr_img_path):
                     print(f"Warning: No matching LR image found for {image_id}. Skipping.")
                     continue

            # Load LR image
            lr_pil = Image.open(lr_img_path).convert('RGB')
            lr_np = np.array(lr_pil)
            # --- END UPDATED LOGIC ---

            dataset.append((lr_np, hr_np, image_id))
        except Exception as e:
            print(f"Warning: Failed to load or process image {img_path}. Error: {e}")

    print(f"   Successfully loaded and processed {len(dataset)} images.")
    return dataset


# --- Execution Block for Analysis ---

if __name__ == "__main__":
    if not os.path.exists(BEST_WEIGHTS_PATH):
        print(f"Error: Weights file '{BEST_WEIGHTS_PATH}' not found.")
        print("Please ensure you run edsr_training.py first to create the weights.")
    else:
        print("1. Loading EDSR model and weights...")
        try:
            # 1. Build Model and Load Weights
            # Must use the same model architecture as training: 32 filters, 8 blocks
            model = make_model(num_filters=32, num_of_residual_blocks=8)
            model.load_weights(BEST_WEIGHTS_PATH)
            print(f"   Model weights loaded successfully from {BEST_WEIGHTS_PATH}.")

            # 2. Load Test Data (from local BSDS100 folder)
            print(f"\n2. Loading test dataset: {DATASET_DISPLAY_NAME}")
            # Pass both HR and LR paths to the loader
            test_dataset = load_bsds100_local(BSDS100_HR_PATH, BSDS100_LR_PATH)

            if not test_dataset:
                raise Exception("Dataset loading failed. Aborting analysis.")

            # 3. Run full benchmark
            print(f"\n3. Running benchmark on all {len(test_dataset)} images (up to {NUM_TEST_IMAGES})...")

            all_psnr_bicubic = []
            all_ssim_bicubic = []
            all_psnr_edsr = []
            all_ssim_edsr = []

            target_image_found = False

            # Use NUM_TEST_IMAGES to limit the loop
            for i, (lowres_np, highres_np, image_id) in enumerate(test_dataset):
                if i >= NUM_TEST_IMAGES:
                    print(f"   Reached test limit of {NUM_TEST_IMAGES} images. Stopping benchmark.")
                    break

                if (len(all_psnr_edsr) % 5 == 0): # Print progress every 5 images
                     print(f"   Processing image {len(all_psnr_edsr)+1}/{len(test_dataset)} (ID: {image_id})...")

                # Generate Bicubic Baseline
                bicubic_image = get_bicubic_upscale(lowres_np)

                # Generate Super-Resolution (SR) Image
                sr_image = upscale_image(model, lowres_np)

                # Calculate metrics for Bicubic
                psnr_b, ssim_b = calculate_metrics(highres_np, bicubic_image)
                all_psnr_bicubic.append(psnr_b)
                all_ssim_bicubic.append(ssim_b)

                # Calculate metrics for EDSR
                psnr_e, ssim_e = calculate_metrics(highres_np, sr_image)
                all_psnr_edsr.append(psnr_e)
                all_ssim_edsr.append(ssim_e)

                # --- Target Image Check ---
                if image_id == TARGET_IMAGE_ID:
                    target_image_found = True
                    print(f"\n--- TARGET IMAGE FOUND: {image_id} ---")
                    print(f"   Bicubic -> PSNR: {psnr_b:.2f} dB | SSIM: {ssim_b:.4f}")
                    print(f"   EDSR    -> PSNR: {psnr_e:.2f} dB | SSIM: {ssim_e:.4f}")
                    # Plot the results for this specific image
                    plot_results(lowres_np, bicubic_image, sr_image, highres_np,
                                 psnr_b, ssim_b, psnr_e, ssim_e, image_id)
                    print("--------------------------------------\n")

            if not target_image_found:
                print(f"\nWarning: Target image '{TARGET_IMAGE_ID}' was not found in the dataset.")

            # 4. Print Final Averaged Results
            print("\n--- FINAL BENCHMARK RESULTS (Averaged) ---")
            print(f"Dataset: {DATASET_DISPLAY_NAME} ({len(all_psnr_edsr)} images processed)")
            print("----------------------------------------------")
            print(f"Bicubic (Baseline): PSNR: {np.mean(all_psnr_bicubic):.2f} dB | SSIM: {np.mean(all_ssim_bicubic):.4f}")
            print(f"EDSR (Our Model):   PSNR: {np.mean(all_psnr_edsr):.2f} dB | SSIM: {np.mean(all_ssim_edsr):.4f}")
            print("----------------------------------------------")
            print(f"PSNR Improvement: {np.mean(all_psnr_edsr) - np.mean(all_psnr_bicubic):.2f} dB")
            print(f"SSIM Improvement: {np.mean(all_ssim_edsr) - np.mean(all_ssim_bicubic):.4f}")
            print("\nAnalysis complete.")

        except Exception as e:
            print(f"\nAn error occurred during analysis: {e}")

import os
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np

from tensorflow import keras
from tensorflow.keras import layers

# --- Global Constants (Must match training script) ---
BEST_WEIGHTS_PATH = "best-model.weights.h5"
# This determines the size of the crop we'll use for the final visualization
VISUAL_CROP_SIZE = 200

# --- STABLE CONFIGURATION FOR TEST DATASET ---
# BSDS100 is not loading in this environment. We use DIV2K's *validation* split
# as a stable and unseen benchmark set for generating comparison metrics (PSNR/SSIM).
TEST_DATASET_TFDS_NAME = 'div2k/bicubic_x4'


# --- Model Architecture Functions (Copied from edsr_training.py) ---

def ResBlock(inputs):
    """EDSR Residual Block."""
    num_filters = inputs.shape[-1]
    x = layers.Conv2D(num_filters, 3, padding="same", activation="relu")(inputs)
    x = layers.Conv2D(num_filters, 3, padding="same")(x)
    x = layers.Add()([inputs, x])
    return x

def Upsampling(inputs, factor=4, **kwargs):
    """Pixel Shuffle/Sub-pixel convolution layer for 4x upscaling."""
    x = layers.Conv2D(64 * (factor ** 2), 3, padding="same", **kwargs)(inputs)
    x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, block_size=factor),
                      name=f"pixel_shuffle_{factor}x")(x)
    return x

def make_model(num_filters, num_of_residual_blocks):
    """Constructs the EDSR Model architecture."""
    input_layer = layers.Input(shape=(None, None, 3))
    x = layers.Rescaling(scale=1.0 / 255)(input_layer)
    x = x_new = layers.Conv2D(num_filters, 3, padding="same")(x)

    for _ in range(num_of_residual_blocks):
        x_new = ResBlock(x_new)

    x_new = layers.Conv2D(num_filters, 3, padding="same")(x_new)
    x = layers.Add()([x, x_new])
    x = Upsampling(x, factor=4)

    # Output is normalized [0, 1]
    output_layer = layers.Conv2D(3, 3, padding="same", activation="sigmoid")(x)
    return keras.Model(input_layer, output_layer)

# --- Metric Functions (Used for analysis, ensuring SSIM is available) ---
def psnr_corrected(y_true, y_pred):
    """Calculates PSNR for inputs normalized to [0, 1]."""
    y_true_float = tf.cast(y_true, tf.float32)
    y_true_normalized = y_true_float / 255.0
    return tf.image.psnr(y_true_normalized, y_pred, max_val=1.0)

def ssim_corrected(y_true, y_pred):
    """Calculates SSIM for inputs normalized to [0, 1]."""
    y_true_float = tf.cast(y_true, tf.float32)
    y_true_normalized = y_true_float / 255.0
    return tf.reduce_mean(tf.image.ssim(y_true_normalized, y_pred, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03))


# --- Inference and Utility Functions ---

def upscale_image(model, lowres):
    """
    Takes (H, W, C) LR image and returns (4H, 4W, C) SR image using the EDSR model.
    """
    model_inputs = tf.expand_dims(lowres, axis=0)
    SR = model(model_inputs, training=False)
    SR = SR * 255.0
    SR = tf.clip_by_value(SR, 0, 255)
    SR = tf.round(SR)
    SR = tf.cast(SR, tf.uint8)
    SR = tf.squeeze(SR, axis=0)
    return SR

def get_bicubic_upscale(lowres_img):
    """Performs 4x Bicubic interpolation for the baseline comparison."""
    lowres_float = tf.cast(lowres_img, tf.float32)
    bicubic = tf.image.resize(
        lowres_float,
        [tf.shape(lowres_img)[0] * 4, tf.shape(lowres_img)[1] * 4],
        method=tf.image.ResizeMethod.BICUBIC
    )
    return tf.cast(bicubic, tf.uint8)

def calculate_metrics(hr_img, upscaled_img):
    """Calculates PSNR and SSIM between ground truth (HR) and an upscaled image."""
    # Metrics need inputs to be normalized to the same scale. We'll use [0, 1].
    hr_float = tf.cast(hr_img, tf.float32) / 255.0
    upscaled_float = tf.cast(upscaled_img, tf.float32) / 255.0

    psnr_val = tf.image.psnr(hr_float, upscaled_float, max_val=1.0).numpy()
    ssim_val = tf.image.ssim(hr_float, upscaled_float, max_val=1.0).numpy()

    # Take the mean of SSIM across the channels and spatial dimensions for a single score
    ssim_val_mean = np.mean(ssim_val)

    return psnr_val, ssim_val_mean


def plot_results(lowres, bicubic, sr, highres):
    """Plots the 4 comparison images."""

    psnr_bicubic, ssim_bicubic = calculate_metrics(highres, bicubic)
    psnr_edsr, ssim_edsr = calculate_metrics(highres, sr)

    plt.figure(figsize=(18, 18))

    # 1. Low Resolution Input
    plt.subplot(2, 2, 1)
    plt.imshow(lowres.numpy())
    plt.title(f"A. Low Resolution Input ({lowres.shape[0]}x{lowres.shape[1]})", fontsize=14)
    plt.axis('off')

    # 2. Bicubic Upscaling (Baseline)
    plt.subplot(2, 2, 2)
    plt.imshow(bicubic.numpy())
    plt.title(f"B. Bicubic Baseline (PSNR: {psnr_bicubic:.2f} dB, SSIM: {ssim_bicubic:.4f})", fontsize=14)
    plt.axis('off')

    # 3. EDSR Model Output (SR)
    plt.subplot(2, 2, 3)
    plt.imshow(sr.numpy())
    plt.title(f"C. EDSR Output (PSNR: {psnr_edsr:.2f} dB, SSIM: {ssim_edsr:.4f})", fontsize=14, color='darkgreen', fontweight='bold')
    plt.axis('off')

    # 4. High Resolution Ground Truth
    plt.subplot(2, 2, 4)
    plt.imshow(highres.numpy())
    plt.title(f"D. High Resolution Ground Truth ({highres.shape[0]}x{highres.shape[1]})", fontsize=14)
    plt.axis('off')

    # Note on the Test Set being used
    dataset_name_clean = "DIV2K (Validation Split)"
    plt.suptitle(f"Super-Resolution Comparison (4x Factor, Test Set: {dataset_name_clean})", fontsize=16, fontweight='bold')
    print("\nQualitative comparison plot generated.")


# --- Execution Block for Analysis ---

if __name__ == "__main__":
    # Based on user's training log
    EXPECTED_AVERAGE_PSNR = "26.25 dB (Epoch 25)"

    if not os.path.exists(BEST_WEIGHTS_PATH):
        print(f"Error: Weights file '{BEST_WEIGHTS_PATH}' not found.")
        print("Please ensure you run edsr_training.py first to create the weights.")
        exit()

    print("1. Loading EDSR model and weights...")
    # 1. Build Model and Load Weights (Must match training architecture: 32 filters, 8 blocks)
    model = make_model(num_filters=32, num_of_residual_blocks=8)
    model.load_weights(BEST_WEIGHTS_PATH)
    print(f"   Model weights loaded successfully from {BEST_WEIGHTS_PATH}.")
    print(f"\nREMINDER: The full model PSNR was {EXPECTED_AVERAGE_PSNR}. The metrics below are for a single image/crop only.")

    # 2. Load Validation Data (uncropped, unbatched)
    split_name = 'validation'
    val = None # Initialize val to None

    try:
        print(f"   Attempting to load data from dataset: {TEST_DATASET_TFDS_NAME}, split: '{split_name}'.")
        val, _ = tfds.load(TEST_DATASET_TFDS_NAME, split=split_name, as_supervised=True, with_info=True)
    except Exception as e:
        print(f"Error loading dataset {TEST_DATASET_TFDS_NAME}: {e}")
        print("\n--- CRITICAL ERROR ---")
        print("Dataset failed to load. Please verify the TFDS name.")
        exit()

    if val is not None:

        # We take the first image from the validation set once
        lowres_full, highres_full = next(iter(val.take(1)))

        NUM_TEST_CROPS = 5
        results = []

        print(f"2. Running inference on {NUM_TEST_CROPS} random crops from the selected image...")

        # Determine the full-resolution PSNR and SSIM for the full image
        SR_full = upscale_image(model, lowres_full)
        Bicubic_full = get_bicubic_upscale(lowres_full)

        psnr_full_edsr, ssim_full_edsr = calculate_metrics(highres_full, SR_full)
        psnr_full_bicubic, ssim_full_bicubic = calculate_metrics(highres_full, Bicubic_full)

        print(f"\n--- Full Image Metrics (Calculated on image 1 of DIV2K Validation Set) ---")
        print(f"Full Image Bicubic PSNR: {psnr_full_bicubic:.2f} dB, SSIM: {ssim_full_bicubic:.4f}")
        print(f"Full Image EDSR PSNR: {psnr_full_edsr:.2f} dB, SSIM: {ssim_full_edsr:.4f}")
        print("--------------------------------------------------------------------------\n")

        for i in range(NUM_TEST_CROPS):
            # 3. Crop a small region from the uncropped image for visualization
            scale = 4
            lr_crop_size = VISUAL_CROP_SIZE // scale

            # Get a random offset for cropping
            lowres_full_shape = tf.shape(lowres_full)[:2]
            max_h = lowres_full_shape[0] - lr_crop_size + 1
            max_w = lowres_full_shape[1] - lr_crop_size + 1

            # Ensure we don't try to crop outside the image bounds
            offset_h = tf.random.uniform(shape=(), maxval=tf.maximum(1, max_h), dtype=tf.int32)
            offset_w = tf.random.uniform(shape=(), maxval=tf.maximum(1, max_w), dtype=tf.int32)

            # Crop the LR input
            lowres_crop = lowres_full[
                offset_h : offset_h + lr_crop_size,
                offset_w : offset_w + lr_crop_size,
            ]

            # Crop the corresponding HR ground truth
            highres_crop = highres_full[
                offset_h * scale : (offset_h + lr_crop_size) * scale,
                offset_w * scale : (offset_w + lr_crop_size) * scale,
            ]

            # 4. Generate Super-Resolution (SR) Image
            SR_image = upscale_image(model, lowres_crop)

            # 5. Generate Bicubic Baseline
            Bicubic_image = get_bicubic_upscale(lowres_crop)

            # 6. Calculate PSNRs and SSIMs
            psnr_bicubic, ssim_bicubic = calculate_metrics(highres_crop, Bicubic_image)
            psnr_edsr, ssim_edsr = calculate_metrics(highres_crop, SR_image)

            results.append({
                'Sample': i + 1,
                'Bicubic PSNR': psnr_bicubic,
                'EDSR PSNR': psnr_edsr,
                'Bicubic SSIM': ssim_bicubic,
                'EDSR SSIM': ssim_edsr
            })

            if i == 0: # Plot the first result only
                print(f"3. Generating plot for Sample 1 (LR crop size {lowres_crop.shape.as_list()})...")
                plot_results(lowres_crop, Bicubic_image, SR_image, highres_crop)

        print("\n--- PSNR & SSIM Comparison for Multiple Random Crops ---")
        for res in results:
            psnr_diff = res['EDSR PSNR'] - res['Bicubic PSNR']
            ssim_diff = res['EDSR SSIM'] - res['Bicubic SSIM']

            # Determine win/loss status based on PSNR delta
            status = "WIN" if psnr_diff > 0.05 else ("LOSS" if psnr_diff < -0.05 else "TIE")

            print(f"Sample {res['Sample']} (PSNR/{status}): Bicubic: {res['Bicubic PSNR']:.2f} dB, SSIM: {res['Bicubic SSIM']:.4f} | EDSR: {res['EDSR PSNR']:.2f} dB, SSIM: {res['EDSR SSIM']:.4f}")
        print("----------------------------------------------------------")
    else:
        print("\nAnalysis could not run because the dataset failed to load.")